{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d344344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "#neural networks with 3 inputs\n",
    "inputs = [1,2,3]\n",
    "weights = [0.2,0.8,-0.5]\n",
    "\n",
    "bias = 2\n",
    "\n",
    "outputs = (inputs[0] * weights[0] + inputs[1]* weights[1] + inputs[2] * weights[2]) +bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f815ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "#now lets say i wanna add neuron with 4 inputs\n",
    "inputs = [1,2,3,2.5]\n",
    "weights = [0.2,0.8,-0.5,1.0]\n",
    "bias = 2\n",
    "\n",
    "outputs = (inputs[0] * weights[0] + inputs[1]* weights[1] + inputs[2] * weights[2] + inputs[3] * weights[3]) +bias\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52a86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now calculating a layer of neurons\n",
    "\n",
    "inputs = [1,2,3,2.5]\n",
    "weights = [[0.2,0.8,-0.5,1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e204bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f973bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "#now using numpy\n",
    "\n",
    "import numpy as np\n",
    "inputs =[1.0,2.0,3.0,2.5]\n",
    "weights = [0.2,0.8,-0.5,1.0]\n",
    "bias = 2.0\n",
    "outputs = np.dot(weights,inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada2d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs =[1.0,2.0,3.0 ,2.5]\n",
    "weights =[[0.2,0.8,-0.5,1.0],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26,-0.27,0.17,0.87]]\n",
    "\n",
    "biases = [2.0,3.0,0.5]\n",
    "\n",
    "#toh jab matrix aa jaata toh toh direct \n",
    "#np.dot(matrix,vector) karte\n",
    "#toh matrcx hai weihgts ka\n",
    "#aur aise kyu karte yuki dot prodcut of weights, inputs is what we need\n",
    "#the dot product of (inputs, weights) is meaningless\n",
    "#agr matrix hoga toh \n",
    "#so we take matrix firsst\n",
    "\n",
    "outputs = np.dot(weights,inputs) + biases\n",
    "\n",
    "#ye biases direct add hojayega kyuki matrix same size ka aeygea\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cc20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "#Now for the batches of inputs\n",
    "inputs = [[1.0,2.0,3.0,2.5],\n",
    "          [2.0,5.0,-1.0,2.0],\n",
    "          [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "weights = [[0.2,0.8,-0.5,1.0],\n",
    "            [0.5,-0.91,0.26,-0.5],\n",
    "            [-0.26,-0.27,0.17,0.87]]\n",
    "\n",
    "biases = [2.0,3.0,0.5]\n",
    "\n",
    "outputs = np.dot(inputs,np.array(weights).T)+ biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6e237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now creating a class for desne layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55ba018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will give us a template on how to implement the whole class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98100bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by doing this we can just directly call an instant and run the coed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c62347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-1.0475188e-04  1.1395361e-04 -4.7983500e-05]\n",
      " [-2.7414842e-04  3.1729150e-04 -8.6921798e-05]\n",
      " [-4.2188365e-04  5.2666257e-04 -5.5912682e-05]\n",
      " [-5.7707680e-04  7.1401405e-04 -8.9430439e-05]\n",
      " [-3.5430698e-04  3.5025488e-04 -2.3363481e-04]\n",
      " [-8.9267001e-04  1.0767876e-03 -1.9453237e-04]\n",
      " [-9.3350781e-04  1.0723802e-03 -3.1227397e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "\n",
    "#Now for creation of the layer\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        #this init function is called automatically whenever the\n",
    "        #instant of this Layer_Dense class is created\n",
    "        # now the function of this init function is to intialise the weights of the layer\n",
    "        # and initailise the biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "        #ham starting mei saare biases ko same initialisation dedete 0s se\n",
    "        #but moving forward inka bias differently update hota based on the gradients\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #calculating the output values\n",
    "        self.output = np.dot(inputs,self.weights) + self.biases\n",
    "        \n",
    "#ab create karte hai dataset\n",
    "X, y = spiral_data(samples = 100, classes =3)\n",
    "#ye hamei 100 points ke teen spiral dega as classes are 3 aur har spiral will have 100 points in it\n",
    "\n",
    "#Now creating a dense layer wiht 2 input features and 3 neurons\n",
    "\n",
    "dense_layer1 = Layer_Dense(2,3)\n",
    "\n",
    "\n",
    "#ab layer bangyii toh uska output nikaal dete hai\n",
    "dense_layer1.forward(X)\n",
    "\n",
    "#ab X hamara input hai aur y is the thing we want to predict here\n",
    "#so thats why we pass dense_layer1.forward(X) only X is passed here thats why\n",
    "\n",
    "#now to check output for some samples\n",
    "print(dense_layer1.output[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "624cd02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.70334781e-04  3.30507901e-05  4.51893320e-05  2.80951153e-05\n",
      "   6.54213000e-05]\n",
      " [-4.36228729e-04  8.66227783e-05 -1.74717206e-05  1.67510298e-04\n",
      "   4.94227424e-05]\n",
      " [-6.38892991e-04  1.26491053e-04 -3.43322569e-07  2.27221681e-04\n",
      "   9.47710214e-05]\n",
      " [-9.04552580e-04  1.80725969e-04 -1.10736255e-04  4.00796242e-04\n",
      "   3.64095868e-05]\n",
      " [-1.14665646e-03  2.30427613e-04 -2.29891331e-04  5.72288234e-04\n",
      "  -3.32274030e-05]]\n"
     ]
    }
   ],
   "source": [
    "dense_layer2 = Layer_Dense(2,5)\n",
    "X1,y1 = spiral_data(samples=100, classes = 5)\n",
    "\n",
    "dense_layer2.forward(X1)\n",
    "\n",
    "print(dense_layer2.output[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "739340cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "A = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "print(np.sum(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49b9f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(A,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee6af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.max(A,axis=1,keepdims=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d78b392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(np.max(A,axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cda4f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dekh keepdims = true karne aur na karne mei\n",
    "#Agr keep dims = true nahi krenge toh ye return karta hai ek 1 dimensional array\n",
    "#jo ki yaha pe return kar raha hai abhi in the case of keepdims= true pe\n",
    "#true rakhne pe wo matrix ka shape maintain krta hai and will be returning the 3,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc05a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 18])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171d79d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07452065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(A,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38badfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.max(A,axis=0,keepdims=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de00f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay so this is done now we will be working with the actvation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c2b0007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  2.  0.  3.3 0.  1.1 2.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "#implementing Activation function Relu\n",
    "import numpy as np\n",
    "inputs = [0,2,-1,3.3,-2.7 ,1.1,2.2,-100]\n",
    "#ye tere inputs hogye \n",
    "#ab tuje pata hai relu function hota max(0,x)\n",
    "#where x is your input theeke\n",
    "outputs = np.maximum(0,inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f9e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now creating a reusable class for the relu function\n",
    "class Activation_ReLU:\n",
    "    #ab forward pass iska \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92beac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06414769 0.17437149 0.47399085 0.28748998]\n",
      " [0.04517666 0.90739747 0.00224921 0.04517666]\n",
      " [0.00522984 0.34875873 0.63547983 0.0105316 ]]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#now implementing softmax\n",
    "inputs = [[1,2,3,2.5],\n",
    "          [2,5,-1,2],\n",
    "          [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "#So first we will be getting unnormalised probabilites\n",
    "exp_values = np.exp(inputs - np.max(inputs,axis =1,keepdims =True))\n",
    "\n",
    "#aur yaha pe subtract kyu krte taaki overflow na hojaaye\n",
    "#kyuki when we take exponent the data overflows so to avoid it\n",
    "#we subtract by the maximal value\n",
    "#this will give us negative values andatleast one zero\n",
    "#aur exponent of -ve values is small\n",
    "#so overflow is solved\n",
    "\n",
    "#now calculating probabilites\n",
    "probabilities = exp_values / np.sum(exp_values,axis=1,keepdims=True)\n",
    "print(probabilities)\n",
    "\n",
    "#ye hamei probabilities dedega\n",
    "\n",
    "\n",
    "#ab to cross check the sum of the probabilites should be 1\n",
    "#but row wise check karenge\n",
    "#kyuki inputs bactches mei aare\n",
    "#aur ek batch ek row hai\n",
    "print(np.sum(probabilities,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebd10a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now creating softmax activation function class\n",
    "class Activation_Softmax:\n",
    "    def forward(self,inputs):\n",
    "        #Get normalised probabilites\n",
    "        exp_values = np.exp(inputs - np.max(inputs,axis =1,keepdims =True))\n",
    "        \n",
    "        probabilities = exp_values / np.sum(exp_values,axis =1 , keepdims = True)\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd5e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333305 0.33333322 0.33333376]\n",
      " [0.33333233 0.333333   0.33333468]\n",
      " [0.33333322 0.33333325 0.3333335 ]\n",
      " [0.33333117 0.33333263 0.3333362 ]]\n"
     ]
    }
   ],
   "source": [
    "X,y = spiral_data(samples=100,classes =3)\n",
    "#this will create our dataset which will have 3 spirals and each will be having a sample of 100 pts\n",
    "\n",
    "#now coming to creating a dense layer we will be having a dense layer with 2 input features and 3 outputs\n",
    "\n",
    "dense1 = Layer_Dense(2,3)\n",
    "\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "\n",
    "#Now creating a second dense layer which will be having the output of the first layer and will be generating the output as 3 outputs\n",
    "\n",
    "dense2 =  Layer_Dense(3,3)\n",
    "\n",
    "#now the activation function here would be spftmnax\n",
    "#since we need classification\n",
    "\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "#Now we will be making a forward pass of our 1 st layer\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "#Now we will be taking the forward pass of the activation function \n",
    "#this will be taking the output of the first layer nad then it will be passed to the activation function\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "#why we add activation function to the outputs to the first layer\n",
    "#since we need to add non linearity and this will help in capturing the complex elements of our layer\n",
    "\n",
    "\n",
    "#Now the second layer will be taking the outputs of the activation function from the 1st layer\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "#Now we will be making forward pass throught activation function\n",
    "#it will take the output of the second dense layer\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c763b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building up the cross entropy loss function building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef6466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.9]\n"
     ]
    }
   ],
   "source": [
    "#hampe kya hoga dataset se softmax_outputs aayenge\n",
    "#ham maan re hai abhi ki hamara data 3 class mei categorise krre hai\n",
    "#ham abhi jo ki hai red green blue\n",
    "#aur fir ham isme cross entropy loss calculate karenge\n",
    "#jiska formula toh categorised standard hai\n",
    "#but \n",
    "softmax_outputs = np.array([[0.7,0.1,0.2],\n",
    "                            [0.1,0.5,0.4],\n",
    "                            [0.02,0.9,0.08]])\n",
    "\n",
    "#yaha pe har ek row ek input of data bata ra hai hamei\n",
    "#for example 0.7 , 0.1, 0.2\n",
    "#ye batara the confidence of being red is 0.7  and of green is 0.1 and of the blue is 0.2\n",
    "#aur har ek row hamara har ek dataset ke barei mei bata ta hai\n",
    "\n",
    "\n",
    "class_targets = [0,1,1]\n",
    "#ab class targets hai hamarei true prediction\n",
    "#yaha pe 0 is for red 1 is for green 2 is for blue\n",
    "#toh true prediction hai jo matlb true data mei 1st data mei aara hai\n",
    "#red and then green and green respectively\n",
    "\n",
    "print(softmax_outputs[[0,1,2],class_targets])\n",
    "\n",
    "#ab ye print statement aise kaam karta ki\n",
    "#softamax_ouptuts matrix pe hamne rows define kardi [0,1,2]\n",
    "#but jo column hai wo ye lera hai class targets se\n",
    "#mtlb [0,1,1]\n",
    "#toh combination bnre hia [0,0], [1,1],[2,1]\n",
    "#jo ki max probabale answer dega softmax outputs se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96f6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ab agr hamara data one hot encoded hai toh\n",
    "#ham kaise extract karenge relevant predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a31a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding mei sirf 1 correct waale pe hota\n",
    "#aur baaki sab 0 hote hai\n",
    "y_true_check = np.array([\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "y_pred_clipped_check = np.array([\n",
    "    [0.2,0.7,0.1],\n",
    "    [0.8,0.1,0.1],\n",
    "    [0.1,0.2,0.7]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17448d9a",
   "metadata": {},
   "source": [
    "To calculate loss using one hot encoded method\n",
    "ham phle element wise multiplication krte\n",
    "fir ham sum karte along the column\n",
    "and then take -ve log \n",
    "and then take mena of the final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e26ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = y_true_check * y_pred_clipped_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca38d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.sum(A,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd449ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = -np.log(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd386e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mean(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipelined",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
